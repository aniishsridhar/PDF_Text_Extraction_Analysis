{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhUAtkMnI6RS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install pdfminer\n",
        "!pip install pdfplumber\n",
        "!pip install pytesseract\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "dNg3xXLD3F_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKfSrhIkSS6G"
      },
      "outputs": [],
      "source": [
        "# To read the PDF\n",
        "import PyPDF2\n",
        "# To analyze the PDF layout and extract text\n",
        "from pdfminer.high_level import extract_pages, extract_text\n",
        "from pdfminer.layout import LTTextContainer, LTChar, LTRect, LTFigure\n",
        "# To extract text from tables in PDF\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "import pandas as pd\n",
        "# To remove the additional created files\n",
        "import os\n",
        "import glob\n",
        "from pypdf import PdfReader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPCer2D7H-q-"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjiBhWIaRpXy"
      },
      "outputs": [],
      "source": [
        "# Create a function to extract text\n",
        "\n",
        "def text_extraction(element):\n",
        "    # Extracting the text from the in-line text element\n",
        "    line_text = element.get_text()\n",
        "    # Find the formats of the text\n",
        "    # Initialize the list with all the formats that appeared in the line of text\n",
        "    line_formats = []\n",
        "    for text_line in element:\n",
        "        if isinstance(text_line, LTTextContainer):\n",
        "            # Iterating through each character in the line of text\n",
        "            for character in text_line:\n",
        "                if isinstance(character, LTChar):\n",
        "                    # Append the font name of the character\n",
        "                    line_formats.append(character.fontname)\n",
        "                    # Append the font size of the character\n",
        "                    line_formats.append(character.size)\n",
        "    # Find the unique font sizes and names in the line\n",
        "    format_per_line = list(set(line_formats))\n",
        "\n",
        "    # Return a tuple with the text in each line along with its format\n",
        "    return (line_text, format_per_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9SXqufZSIx_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This is formatted as code\n",
        "\n",
        "# Find the PDF path\n",
        "#pdf_path = 'Apple_Earnings.pdf'\n",
        "\n",
        "def extract_pdf(path_pdf):\n",
        "# create a PDF file object\n",
        "  pdfFileObj = open(path_pdf, 'rb')\n",
        "# create a PDF reader object\n",
        "  pdfReaded = PyPDF2.PdfReader(pdfFileObj)\n",
        "# Create the dictionary to extract text from each image\n",
        "  text_per_page = {}\n",
        "# We extract the pages from the PDF\n",
        "  for pagenum, page in enumerate(extract_pages(path_pdf)):\n",
        "    # Initialize the variables needed for the text extraction from the page\n",
        "    pageObj = pdfReaded.pages[pagenum]\n",
        "    page_text = []\n",
        "    line_format = []\n",
        "    text_from_images = []\n",
        "    text_from_tables = []\n",
        "    page_content = []\n",
        "    # Initialize the number of the examined tables\n",
        "    table_num = 0\n",
        "    first_element= True\n",
        "    table_extraction_flag= False\n",
        "    # Open the pdf file\n",
        "    pdf = pdfplumber.open(path_pdf)\n",
        "    # Find the examined page\n",
        "    page_tables = pdf.pages[pagenum]\n",
        "    # Find the number of tables on the page\n",
        "    tables = page_tables.find_tables()\n",
        "\n",
        "\n",
        "    # Find all the elements\n",
        "    page_elements = [(element.y1, element) for element in page._objs]\n",
        "    # Sort all the elements as they appear in the page\n",
        "    page_elements.sort(key=lambda a: a[0], reverse=True)\n",
        "\n",
        "    # Find the elements that composed a page\n",
        "    for i,component in enumerate(page_elements):\n",
        "        # Extract the position of the top side of the element in the PDF\n",
        "        pos= component[0]\n",
        "        # Extract the element of the page layout\n",
        "        element = component[1]\n",
        "\n",
        "        # Check if the element is a text element\n",
        "        if isinstance(element, LTTextContainer):\n",
        "            # Check if the text appeared in a table\n",
        "            if table_extraction_flag == False:\n",
        "                # Use the function to extract the text and format for each text element\n",
        "                (line_text, format_per_line) = text_extraction(element)\n",
        "                # Append the text of each line to the page text\n",
        "                page_text.append(line_text)\n",
        "                # Append the format for each line containing text\n",
        "                line_format.append(format_per_line)\n",
        "                page_content.append(line_text)\n",
        "            else:\n",
        "                # Omit the text that appeared in a table\n",
        "                pass\n",
        "\n",
        "        # Check the elements for images\n",
        "\n",
        "\n",
        "    # Create the key of the dictionary\n",
        "    dctkey = 'Page_'+str(pagenum)\n",
        "    # Add the list of list as the value of the page key\n",
        "    text_per_page[dctkey]= [page_text, line_format, page_content]\n",
        "\n",
        "# Closing the pdf file object\n",
        "  pdfFileObj.close()\n",
        "  return text_per_page\n",
        "\n",
        "\n",
        "dict_text = extract_pdf(\"appl_q2_2023.pdf\")\n",
        "print(dict_text)\n",
        "\n",
        "# Display the content of the page\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comp_name + \"-\" + date_val"
      ],
      "metadata": {
        "id": "rQTcoSMZ32Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_page_num(dict_text):\n",
        "  page_num = \"\"\n",
        "  index_trunc = 0\n",
        "  for values in dict_text:\n",
        "    if 'Questions And Answers\\n' in dict_text[values][0]:\n",
        "      page_num = values\n",
        "      index_trunc = dict_text[values][0].index('Questions And Answers\\n')\n",
        "      break\n",
        "  return [page_num, index_trunc]\n",
        "\n",
        "\n",
        "def concat_text(dict_text):\n",
        "  lst_speech = []\n",
        "  trunc_set = get_page_num(dict_text)\n",
        "  for values in dict_text:\n",
        "    if values == trunc_set[0]:\n",
        "      lst_speech = lst_speech + dict_text[values][0][2: trunc_set[1]]\n",
        "      return lst_speech\n",
        "    else:\n",
        "      lst_speech = lst_speech + dict_text[values][0][2:-1]\n",
        "\n",
        "def strng_check(comments_lst):\n",
        "  if \"{BIO\" in comments_lst:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def get_all_index(dict_text):\n",
        "  lst_text = concat_text(dict_text)\n",
        "  page_indx = get_page_num(dict_text)\n",
        "  bios_index = [i for i, n in enumerate(lst_text) if strng_check(n) == True]\n",
        "  names_index =  [values - 1 for values in bios_index]\n",
        "  names_values = [lst_text[names][0:-1] for names in names_index]\n",
        "  bios_index.append(len(lst_text) - 1)\n",
        "\n",
        "  author_note_dict = {}\n",
        "  start = 0\n",
        "  end = 0\n",
        "  counter = 0\n",
        "  for names in bios_index[0:-1]:\n",
        "    start = bios_index[counter]\n",
        "    end = bios_index[counter + 1]\n",
        "    author_note_dict[names] = sent_tokenize(' '. join(lst_text[start + 1 : end]))\n",
        "    counter = counter + 1\n",
        "\n",
        "  comp_name = dict_text['Page_0'][0][0].split(\"\\n\")[1].split(\"(\")[1][0:-1].split(\" \")[0]\n",
        "  date_val = dict_text['Page_0'][0][1][0:7]\n",
        "  df_author_notes = pd.DataFrame({\"Author_Name\": names_values,\n",
        "                                  \"Words\": author_note_dict.values(),\n",
        "                                  \"Report_Company\": comp_name + \"-\" + date_val})\n",
        "\n",
        "  df_author_notes = df_author_notes.explode('Words').reset_index(drop=True)\n",
        "\n",
        "\n",
        "  return df_author_notes\n",
        "\n",
        "\n",
        "\n",
        "#[i for i, n in enumerate((text_per_page[\"Page_0\"][0] + text_per_page[\"Page_1\"][0])) if strng_check(n) == True] # List comprehension\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y1DKB7DJ8DOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0EApr2xfNN5"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_all_notes = pd.DataFrame({'Author_Name': [],\n",
        "                             'Words': [],\n",
        "                             'Report_Company': []}, index = [])\n",
        "for file in glob.glob(\"*.pdf\"):\n",
        "  print(file)\n",
        "  pdf_extract = extract_pdf(file)\n",
        "  df_current_report = get_all_index(pdf_extract)\n",
        "  df_all_notes = pd.concat([df_all_notes, df_current_report])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_notes = df_all_notes.reset_index()\n",
        "df_all_notes['Words'] = df_all_notes['Words'].apply(lambda x: ' '.join(x.split(\"\\n\")) if \"\\n\" in x else x)\n",
        "df_all_notes['Words']  = df_all_notes['Words'].apply(lambda x: '-'.join(x.split(\"- \")) if \"- \" in x else x)"
      ],
      "metadata": {
        "id": "z6VzemoYrmp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_notes.head()"
      ],
      "metadata": {
        "id": "TIsG9er7Ew-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E2NWo5CsH0Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_notes.to_csv(\"/content/drive/My Drive/Colab Notebooks/report_text.csv\")"
      ],
      "metadata": {
        "id": "Bv08hNJTlWcX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}